{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f86c1214",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:09.802794Z",
     "iopub.status.busy": "2023-02-17T23:55:09.802156Z",
     "iopub.status.idle": "2023-02-17T23:55:22.494231Z",
     "shell.execute_reply": "2023-02-17T23:55:22.492822Z"
    },
    "id": "pB2bdCYyTIcv",
    "outputId": "af95ea33-f7ae-48ed-c436-c9ba8595b690",
    "papermill": {
     "duration": 12.706365,
     "end_time": "2023-02-17T23:55:22.497493",
     "exception": false,
     "start_time": "2023-02-17T23:55:09.791128",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0073f09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.510210Z",
     "iopub.status.busy": "2023-02-17T23:55:22.509518Z",
     "iopub.status.idle": "2023-02-17T23:55:22.514454Z",
     "shell.execute_reply": "2023-02-17T23:55:22.513071Z"
    },
    "id": "BeztYEKRTM-d",
    "papermill": {
     "duration": 0.01373,
     "end_time": "2023-02-17T23:55:22.516826",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.503096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd7c28a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.528848Z",
     "iopub.status.busy": "2023-02-17T23:55:22.528449Z",
     "iopub.status.idle": "2023-02-17T23:55:22.532607Z",
     "shell.execute_reply": "2023-02-17T23:55:22.531450Z"
    },
    "id": "UZBg40kDTaSr",
    "papermill": {
     "duration": 0.013292,
     "end_time": "2023-02-17T23:55:22.535227",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.521935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data to test code\n",
    "# !tar xvzf /content/drive/MyDrive/GP_project/part3.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8031d666",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.547792Z",
     "iopub.status.busy": "2023-02-17T23:55:22.547005Z",
     "iopub.status.idle": "2023-02-17T23:55:22.552088Z",
     "shell.execute_reply": "2023-02-17T23:55:22.551290Z"
    },
    "id": "Nc_sz_DxThyk",
    "papermill": {
     "duration": 0.014203,
     "end_time": "2023-02-17T23:55:22.554595",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.540392",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##export pytorch model to onnx \n",
    "# ! pip install onnxruntime\n",
    "# !pip --quiet install onnx onnxruntime onnxsim\n",
    "# !pip install onnx-tf\n",
    "# !git clone https://github.com/deepcam-cn/yolov5-face.git\n",
    "# %cd /content/yolov5-face\n",
    "# !git clone https://github.com/hpc203/yolov5-face-landmarks-opencv-v2.git\n",
    "# !python /content/yolov5-face/main_export_onnx.py --cfg /content/yolov5-face/models/yolov5s.yaml --weights /content/drive/MyDrive/GP_project/Weights/yolov5s-face.pt --image /content/yolov5-face-landmarks-opencv-v2/selfie.jpg  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f4eb51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.567083Z",
     "iopub.status.busy": "2023-02-17T23:55:22.566464Z",
     "iopub.status.idle": "2023-02-17T23:55:22.571656Z",
     "shell.execute_reply": "2023-02-17T23:55:22.570262Z"
    },
    "id": "niCBth8Mse73",
    "outputId": "1c57f777-9677-49e2-9e10-8cf1b75d8955",
    "papermill": {
     "duration": 0.014336,
     "end_time": "2023-02-17T23:55:22.574139",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.559803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip3 install --upgrade opencv-python\n",
    "# print(cv2. __version__ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fd844ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.587119Z",
     "iopub.status.busy": "2023-02-17T23:55:22.586285Z",
     "iopub.status.idle": "2023-02-17T23:55:22.591162Z",
     "shell.execute_reply": "2023-02-17T23:55:22.590278Z"
    },
    "id": "-MmU4xEXaJ0G",
    "papermill": {
     "duration": 0.014145,
     "end_time": "2023-02-17T23:55:22.593525",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.579380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## to copy model file from drive to notebook\n",
    "# %cp /content/drive/MyDrive/GP_project/Weights/yolov5s-face.onnx /content/yolov5s-face.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a4d7a1",
   "metadata": {
    "id": "S6AS_itt8uN5",
    "papermill": {
     "duration": 0.005057,
     "end_time": "2023-02-17T23:55:22.603759",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.598702",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Run onnx model using opencv2**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dbd28517",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.616901Z",
     "iopub.status.busy": "2023-02-17T23:55:22.616296Z",
     "iopub.status.idle": "2023-02-17T23:55:22.630833Z",
     "shell.execute_reply": "2023-02-17T23:55:22.629777Z"
    },
    "id": "PudsejZJ9LBU",
    "papermill": {
     "duration": 0.02406,
     "end_time": "2023-02-17T23:55:22.633437",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.609377",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _make_grid(nx=20, ny=20):\n",
    "        xv, yv = np.meshgrid(np.arange(ny), np.arange(nx))\n",
    "        return np.stack((xv, yv), 2).reshape((-1, 2)).astype(np.float32)\n",
    "        \n",
    "\n",
    "\n",
    "def drawPred(frame, conf, left, top, right, bottom, landmark):\n",
    "      \"\"\"plot predicted bounding box and facial landmarks on the image\"\"\"\n",
    "      # Draw a bounding box.\n",
    "      cv2.rectangle(frame, (left, top), (right, bottom), (0, 0, 255), thickness=2)\n",
    "      label = '%.2f' % conf\n",
    "      #Display the label at the top of the bounding box\n",
    "      cv2.putText(frame,label,(left, top - 2),cv2.FONT_HERSHEY_SIMPLEX,0.75,[225, 255, 255],thickness=2) \n",
    "      for i in range(5):\n",
    "          cv2.circle(frame, (landmark[i*2], landmark[i*2+1]), 1, (0,255,0), thickness=-1)\n",
    "      return frame \n",
    "\n",
    "\n",
    "def align_faces(im,bbox, landmark=None):\n",
    "    \"\"\"align predicted face using 5 facial landmarks \n",
    "       and crop it with shape (112,112).\n",
    "       if landmarks don't exis, we crop the image using bounding box \"\"\"\n",
    "    M = None\n",
    "    warped=None\n",
    "    x1 = int(bbox[0])  # rect.left()\n",
    "    y1 = int(bbox[1])  # rect.top()\n",
    "    x2 = int(bbox[2])  # rect.right()\n",
    "    y2 = int(bbox[3])   # rect.bottom()\n",
    "    \n",
    "    if landmark is not None:\n",
    "        src = np.array([\n",
    "          [30.2946, 51.6963],\n",
    "          [65.5318, 51.5014],\n",
    "          [48.0252, 71.7366],\n",
    "          [33.5493, 92.3655],\n",
    "          [62.7299, 92.2041] ], dtype=np.float32 )\n",
    "        src[:,0] += 8.0\n",
    "        dst = landmark.astype(np.float32)\n",
    "        M = cv2.estimateAffine2D(dst,src)[0]\n",
    "        warped = cv2.warpAffine(im,M,(112,112), borderValue = 0.0)\n",
    "    else:\n",
    "        warped = im[y1:y1+y2, x1:x1+x2]\n",
    "    return warped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b97eb88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.646718Z",
     "iopub.status.busy": "2023-02-17T23:55:22.646023Z",
     "iopub.status.idle": "2023-02-17T23:55:22.658224Z",
     "shell.execute_reply": "2023-02-17T23:55:22.657180Z"
    },
    "id": "9ereLepnslqy",
    "papermill": {
     "duration": 0.022019,
     "end_time": "2023-02-17T23:55:22.660838",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.638819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def non_max_supression(frame, outs ,confThreshold=0.3,nmsThreshold=0.45):\n",
    "        frameHeight = frame.shape[0]\n",
    "        frameWidth = frame.shape[1]\n",
    "        \n",
    "        ratioh, ratiow = frameHeight / 640, frameWidth / 640\n",
    "        # Scan through all the bounding boxes output from the network and keep only the\n",
    "        # ones with high confidence scores. Assign the box's class label as the class with the highest score.\n",
    "\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        landmarks = []\n",
    "        #print(outs.shape)\n",
    "        for detection in outs:\n",
    "      \n",
    "            #confidence = detection[15]\n",
    "            conf=detection[4]*detection[15]\n",
    "            #print(conf)\n",
    "            \n",
    "            if detection[4] > confThreshold:\n",
    "                center_x = int(detection[0] * ratiow)\n",
    "                center_y = int(detection[1] * ratioh)\n",
    "                width = int(detection[2] * ratiow)\n",
    "                height = int(detection[3] * ratioh)\n",
    "                left = int(center_x - width / 2)\n",
    "                top = int(center_y - height / 2)\n",
    "\n",
    "                confidences.append(float(conf))\n",
    "                boxes.append([left, top, width, height])\n",
    "                landmark = detection[5:15] * np.tile(np.float32([ratiow,ratioh]), 5)\n",
    "                landmarks.append(landmark.astype(np.int32))\n",
    "        # Perform non maximum suppression to eliminate redundant overlapping boxes with\n",
    "        # lower confidences.\n",
    "        indices = cv2.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "        \n",
    "        return np.array(boxes)[indices],np.array(landmarks)[indices],np.array(confidences)[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a1b9923",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.673746Z",
     "iopub.status.busy": "2023-02-17T23:55:22.673108Z",
     "iopub.status.idle": "2023-02-17T23:55:22.683816Z",
     "shell.execute_reply": "2023-02-17T23:55:22.682057Z"
    },
    "id": "g-ZtmqZWArrA",
    "papermill": {
     "duration": 0.020582,
     "end_time": "2023-02-17T23:55:22.686867",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.666285",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocess(frame,boxes,landmarks,confidences):\n",
    "        \"\"\"filter predicted bboxes, \n",
    "             if exist more than face in the image \n",
    "            ,take the closeset face to the camera using IOD metric\n",
    "            and return image cropped and aligned.\n",
    "            else if there is no faces predicted return None \"\"\"\n",
    "        im=frame.copy()\n",
    "        #im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        max_iod=-1\n",
    "        box_=None\n",
    "        land_mark=None\n",
    "        for box, landmark, confidence in zip(boxes, landmarks, confidences):\n",
    "            lm = [tuple(landmark[i:i + 2]) for i in range(0, len(landmark), 2)]\n",
    "            IOD = abs((lm[0][0] + lm[0][1] / 2.0) - (lm[1][0] + lm[1][1] / 2.0)) #This metric could be used to infer distance from the camera.\n",
    "            if IOD > max_iod:  # filter bbox based on IOD(inter-ocular distance)\n",
    "                  max_iod=IOD\n",
    "                  box_=box\n",
    "                  land_mark=lm \n",
    "            ## draw bounding box and landmarks       \n",
    "            #frame = drawPred(frame, confidence, box[0], box[1], box[0] +  box[2], box[1] + box[3], landmark)\n",
    "        if max_iod != -1:\n",
    "            cropped=align_faces(im.copy(),box_, np.array(land_mark))\n",
    "            # plt.imshow(cropped)\n",
    "            # plt.show()\n",
    "            # path='/content/cropped.jpg'\n",
    "            # cv2.imwrite(path,cropped)    \n",
    "            return cropped\n",
    "        else:\n",
    "           return None   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a72b0ff8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.700492Z",
     "iopub.status.busy": "2023-02-17T23:55:22.700086Z",
     "iopub.status.idle": "2023-02-17T23:55:22.717920Z",
     "shell.execute_reply": "2023-02-17T23:55:22.716421Z"
    },
    "id": "w5RrYN8N99h6",
    "papermill": {
     "duration": 0.02792,
     "end_time": "2023-02-17T23:55:22.720756",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.692836",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_anchors(prediction,inpWidth,inpHeight):\n",
    "        anchors = [[4,5,  8,10,  13,16], [23,29,  43,55,  73,105], [146,217,  231,300,  335,433]]\n",
    "        num_classes = 1\n",
    "        nl = len(anchors)\n",
    "        na = len(anchors[0]) // 2\n",
    "        no = num_classes + 5 + 10\n",
    "        grid = [np.zeros(1)] * nl\n",
    "        stride = np.array([8., 16., 32.])\n",
    "        anchor_grid = np.asarray(anchors, dtype=np.float32).reshape(nl, -1, 2)\n",
    "        \n",
    "        prediction[..., [0,1,2,3,4,15]] = 1 / (1 + np.exp(-prediction[..., [0,1,2,3,4,15]]))   ###sigmoid\n",
    "        row_ind = 0\n",
    "        for i in range(nl):\n",
    "            h, w = int(inpHeight/stride[i]), int(inpWidth/stride[i])\n",
    "            length = int(na * h * w)\n",
    "            if grid[i].shape[2:4] != (h,w):\n",
    "                grid[i] = _make_grid(w, h)\n",
    "            \n",
    "            g_i = np.tile(grid[i], (na, 1))\n",
    "            a_g_i = np.repeat(anchor_grid[i], h * w, axis=0)\n",
    "            prediction[row_ind:row_ind + length, 0:2] = (prediction[row_ind:row_ind + length, 0:2] * 2. - 0.5 + g_i) * int(stride[i])\n",
    "            prediction[row_ind:row_ind + length, 2:4] = (prediction[row_ind:row_ind + length, 2:4] * 2) ** 2 * a_g_i\n",
    "\n",
    "            prediction[row_ind:row_ind + length, 5:7] = prediction[row_ind:row_ind + length, 5:7] * a_g_i + g_i * int(stride[i])   # landmark x1 y1\n",
    "            prediction[row_ind:row_ind + length, 7:9] = prediction[row_ind:row_ind + length, 7:9] * a_g_i + g_i * int(stride[i])  # landmark x2 y2\n",
    "            prediction[row_ind:row_ind + length, 9:11] = prediction[row_ind:row_ind + length, 9:11] * a_g_i + g_i * int(stride[i])  # landmark x3 y3\n",
    "            prediction[row_ind:row_ind + length, 11:13] = prediction[row_ind:row_ind + length, 11:13] * a_g_i + g_i * int(stride[i])  # landmark x4 y4\n",
    "            prediction[row_ind:row_ind + length, 13:15] = prediction[row_ind:row_ind + length, 13:15] * a_g_i + g_i * int(stride[i])  # landmark x5 y5\n",
    "            row_ind += length\n",
    "        return prediction   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74566797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.733517Z",
     "iopub.status.busy": "2023-02-17T23:55:22.733105Z",
     "iopub.status.idle": "2023-02-17T23:55:22.740533Z",
     "shell.execute_reply": "2023-02-17T23:55:22.739152Z"
    },
    "id": "HJuWd3gP83ks",
    "papermill": {
     "duration": 0.016819,
     "end_time": "2023-02-17T23:55:22.742975",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.726156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect(srcimg,model_path,inpWidth,inpHeight):\n",
    "        \n",
    "        #prepare input image\n",
    "        blob = cv2.dnn.blobFromImage(srcimg, 1 / 255.0, (inpWidth, inpHeight), [0, 0, 0], swapRB=True, crop=False)\n",
    "        # read model\n",
    "        net = cv2.dnn.readNet(model_path)\n",
    "        # Sets the input to the network\n",
    "        net.setInput(blob)\n",
    "\n",
    "        # Runs the forward pass to get output of the output layers\n",
    "        outs = net.forward(net.getUnconnectedOutLayersNames())[0]\n",
    "        #print(outs[0, [0,1,2,3,4,15]])\n",
    "        # inference output\n",
    "        outs=process_anchors(outs,inpWidth,inpHeight)\n",
    "        \n",
    "        return outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6e92460",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.755812Z",
     "iopub.status.busy": "2023-02-17T23:55:22.755414Z",
     "iopub.status.idle": "2023-02-17T23:55:22.761936Z",
     "shell.execute_reply": "2023-02-17T23:55:22.760881Z"
    },
    "id": "6GG9WETNBRas",
    "papermill": {
     "duration": 0.016028,
     "end_time": "2023-02-17T23:55:22.764347",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.748319",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def yolov5(srcimg,model_path='/kaggle/input/yolov5/yolov5s-face.onnx',confThreshold=0.3,nmsThreshold=0.45):\n",
    "  #srcimg = cv2.imread(imgpath)\n",
    "  # imname=imgpath.split('/')[-1]\n",
    "  # save_path+='/'+imname\n",
    "  dets = detect(srcimg,model_path,640,640)\n",
    "  boxes,landmarks,confidences=non_max_supression(srcimg, dets)\n",
    "  img = postprocess(srcimg,boxes,landmarks,confidences)\n",
    "  return img\n",
    "  # if img is not None:\n",
    "  #   cv2.imwrite(save_path, img)\n",
    "  # else:\n",
    "  #   print(\"there is no faces in the image\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f6edd81d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.777206Z",
     "iopub.status.busy": "2023-02-17T23:55:22.776400Z",
     "iopub.status.idle": "2023-02-17T23:55:22.781554Z",
     "shell.execute_reply": "2023-02-17T23:55:22.780348Z"
    },
    "id": "jOCC8UxWP4fp",
    "papermill": {
     "duration": 0.014635,
     "end_time": "2023-02-17T23:55:22.784466",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.769831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# #test onnx model\n",
    "# from tqdm import tqdm\n",
    "# import os\n",
    "# for img in tqdm(os.listdir('/content/part3')):\n",
    "#     path = os.path.join('/content/part3', img)\n",
    "#     img_data = cv2.imread(path) # BGR IMAGE\n",
    "#     img_data = cv2.cvtColor(img_data, cv2.COLOR_BGR2RGB)\n",
    "#     img=yolov5(img_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c05909d",
   "metadata": {
    "id": "7a5U64tQPKgf",
    "papermill": {
     "duration": 0.005066,
     "end_time": "2023-02-17T23:55:22.794970",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.789904",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**convert to tflite model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9391dafd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.808046Z",
     "iopub.status.busy": "2023-02-17T23:55:22.807589Z",
     "iopub.status.idle": "2023-02-17T23:55:22.813192Z",
     "shell.execute_reply": "2023-02-17T23:55:22.811830Z"
    },
    "id": "2UEga5m9ARJT",
    "papermill": {
     "duration": 0.015061,
     "end_time": "2023-02-17T23:55:22.815821",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.800760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#export onnx model to tflite \n",
    "# !onnx-tf convert -i /content/yolov5s-face.onnx -o /content/\n",
    "# converter = tf.lite.TFLiteConverter.from_saved_model('/content/')\n",
    "# tflite_model = converter.convert()\n",
    "\n",
    "# with open('/content/yolov5s_model.tflite', 'wb') as f:\n",
    "#   f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "915f16d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.829295Z",
     "iopub.status.busy": "2023-02-17T23:55:22.828843Z",
     "iopub.status.idle": "2023-02-17T23:55:22.837676Z",
     "shell.execute_reply": "2023-02-17T23:55:22.836718Z"
    },
    "id": "S7HZISuZJzca",
    "papermill": {
     "duration": 0.018054,
     "end_time": "2023-02-17T23:55:22.839872",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.821818",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detect_tf_model(srcimg,model_path,inpWidth,inpHeight):\n",
    "   \n",
    "   #prepare input     \n",
    "   blob = cv2.dnn.blobFromImage(srcimg, 1 / 255.0, (inpWidth, inpHeight), [0, 0, 0], swapRB=True, crop=False)\n",
    "   \n",
    "\n",
    "   interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "   #Allocate tensors.\n",
    "   interpreter.allocate_tensors()\n",
    "   # Get input and output tensors.\n",
    "   input_details = interpreter.get_input_details()\n",
    "   output_details = interpreter.get_output_details()\n",
    "\n",
    "   # Test the model on random input data.\n",
    "   input_shape = input_details[0]['shape']\n",
    "   interpreter.set_tensor(input_details[0]['index'], blob)\n",
    "\n",
    "   interpreter.invoke()\n",
    "\n",
    "   # The function `get_tensor()` returns a copy of the tensor data.\n",
    "   # Use `tensor()` in order to get a pointer to the tensor.\n",
    "   output_data = interpreter.get_tensor(output_details[0]['index'])\n",
    "   output_data=process_anchors(output_data,inpWidth,inpHeight)\n",
    "  \n",
    "\n",
    "   return output_data        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8ed3b086",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-17T23:55:22.853294Z",
     "iopub.status.busy": "2023-02-17T23:55:22.852124Z",
     "iopub.status.idle": "2023-02-17T23:55:22.857294Z",
     "shell.execute_reply": "2023-02-17T23:55:22.856344Z"
    },
    "id": "ZxpqZYa6PkXA",
    "papermill": {
     "duration": 0.01434,
     "end_time": "2023-02-17T23:55:22.859685",
     "exception": false,
     "start_time": "2023-02-17T23:55:22.845345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##test tflite model\n",
    "# model_path='/content/yolov5s_model.tflite'\n",
    "# imgpath='/content/3faces.PNG'\n",
    "# srcimg = cv2.imread(imgpath)\n",
    "# dets = detect_tf_model(srcimg,model_path,640,640)\n",
    "# boxes,landmarks,confidences=non_max_supression(srcimg, dets)\n",
    "# img = postprocess(srcimg,boxes,landmarks,confidences)\n",
    "# if img is not None:\n",
    "#     cv2.imwrite('/content/img.jpg', img)\n",
    "# else:\n",
    "#   print(\"there is no faces in the image\") "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 26.27295,
   "end_time": "2023-02-17T23:55:26.309237",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-02-17T23:55:00.036287",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
